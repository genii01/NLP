{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jychoi/anaconda3/envs/ml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konlpy version = 0.5.2\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras\n",
    "import konlpy\n",
    "from konlpy.tag import Komoran, Mecab, Okt, Twitter\n",
    "%matplotlib inline\n",
    "print('konlpy version = {}'.format(konlpy.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('total_dataset.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset[:round(dataset.shape[0]*0.9)]\n",
    "test_data = dataset[round(dataset.shape[0]*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24669\n",
       "1    24552\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2791\n",
       "0    2678\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['contents'] = train_data['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_data['contents'] = test_data['contents'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(train_data[train_data.contents == ' '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '  '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '   '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '    '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '     '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '      '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '       '].index, inplace=True)\n",
    "train_data.drop(train_data[train_data.contents == '        '].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(test_data[test_data.contents == ' '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '  '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '   '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '    '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '     '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '      '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '       '].index, inplace=True)\n",
    "test_data.drop(test_data[test_data.contents == '        '].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(subset = ['contents'], inplace = True)\n",
    "test_data.dropna(subset = ['contents'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_tokenizer setup\n",
    "ko_tokenizer = Komoran()\n",
    "stopwords = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentence word tokenizing time = 55.038\n"
     ]
    }
   ],
   "source": [
    "# sentence word tokenizing for train_data\n",
    "s = time.time()\n",
    "x_train = []\n",
    "for i, sentence in enumerate(train_data['contents']):\n",
    "    temp_X = []\n",
    "    temp_X = list(ko_tokenizer.morphs(sentence)) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    x_train.append(temp_X)\n",
    "print('train sentence word tokenizing time = {:.3f}'.format(time.time() - s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['밴드', '부분', '이', '쪼', 'ㅁ', '크', '네요']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sentence word tokenizing time = 7.200\n"
     ]
    }
   ],
   "source": [
    "# sentensce word tokenizing for test_data\n",
    "s = time.time()\n",
    "x_test =[]\n",
    "for i, sentence in enumerate(test_data['contents']):\n",
    "    temp_x = []\n",
    "    temp_x = list(ko_tokenizer.morphs(sentence))\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    x_test.append(temp_x)\n",
    "print('test sentence word tokenizing time = {:.3f}'.format(time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기한 train contents로 변환\n",
    "tmp_train = []\n",
    "for sentence in x_train:\n",
    "    tmp_x = ' '.join(sentence)\n",
    "    tmp_train.append(tmp_x)\n",
    "\n",
    "train_data['contents'] = tmp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기한 train contents로 변환\n",
    "tmp_test = []\n",
    "for sentence in x_test:\n",
    "    tmp_x = ' '.join(sentence)\n",
    "    tmp_test.append(tmp_x)\n",
    "\n",
    "test_data['contents'] = tmp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 26103\n"
     ]
    }
   ],
   "source": [
    "# word를 index vector로 변환\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "t= Tokenizer()\n",
    "t.fit_on_texts(train_data['contents'])\n",
    "vocab_size = len(t.word_index)+1\n",
    "print('vocab_size = {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sent_onehot generation time = 1.43\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "train_sent_onehot = t.texts_to_sequences(train_data['contents'])\n",
    "print('train_sent_onehot generation time = {:.2f}'.format(time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_sent_onehot generation time = 0.15\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "test_sent_onehot = t.texts_to_sequences(test_data['contents'])\n",
    "print('test_sent_onehot generation time = {:.2f}'.format(time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of contents :  1140\n",
      "average length of contents :  33.97974153696103\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('max length of contents : ', max(len(l) for l in x_train))\n",
    "print('average length of contents : ', sum(map(len, x_train))/len(x_train))\n",
    "plt.hist([len(s) for s in x_train], bins =150)\n",
    "plt.xlabel('length of data')\n",
    "plt.ylabel('number of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(train_sent_onehot, maxlen = 300, padding = 'pre')\n",
    "x_test = pad_sequences(test_sent_onehot, maxlen = 300, padding = 'pre')\n",
    "y_train = train_data['rank'].to_numpy()\n",
    "y_test = test_data['rank'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   65,   89,    9],\n",
       "       [   0,    0,    0, ...,   35,    9,  502],\n",
       "       [   0,    0,    0, ...,  108, 1037,   17],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1357,    1,    9],\n",
       "       [   0,    0,    0, ...,  329,   83,   32],\n",
       "       [   0,    0,    0, ...,  173,   41,   14]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, LSTM, GRU, Bidirectional, Embedding, Dropout, concatenate, Flatten, Activation, MaxPooling1D, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(args):\n",
    "    inputs = Input(shape=(args.max_length,))\n",
    "    if args.embedding_matrix is None:\n",
    "        output = Embedding(vocab_size, 300, trainable = True)(inputs)\n",
    "    else:\n",
    "        output = Embedding(vocab_size, 300, trainable = False, weights=[embedding_matrix])(inputs)    \n",
    "#     output = Embedding(vocab_size, 300, input_length=args.max_length)(inputs)\n",
    "    output = Bidirectional(LSTM(100, return_sequences = True, dropout = args.dropout, recurrent_dropout = 0.1))(output)\n",
    "    output = GlobalMaxPool1D()(output)\n",
    "    output = Dense(100, activation = args.activation,kernel_regularizer=regularizers.l2(1e-4))(output)\n",
    "    output = Dropout(args.dropout)(output)\n",
    "    preds = Dense(1, activation = 'sigmoid')(output)\n",
    "    model = Model(inputs, preds)\n",
    "    try:\n",
    "        model = multi_gpu_model(model, cpu_relocation = True)\n",
    "# model = multi_gpu_model(model, gpus = 2, cpu_relocation = True)\n",
    "        print('#'*50)\n",
    "        print('====> training using multiple gpu')\n",
    "        print('#'*50)\n",
    "    except:\n",
    "        print('#'*50)\n",
    "        print('====> training using single gpu or cpu')\n",
    "        print('#'*50)\n",
    "    return model\n",
    "\n",
    "def build_deep_model(args):\n",
    "    inputs = Input(shape=(args.max_length,))\n",
    "    output = Embedding(vocab_size, 300, input_length=args.max_length)(inputs)\n",
    "    output = Bidirectional(LSTM(100, return_sequences = True, dropout = args.dropout, recurrent_dropout = 0.2))(output)\n",
    "    output = Bidirectional(LSTM(100, return_sequences = True, dropout = args.dropout, recurrent_dropout = 0.2))(output)\n",
    "    output = GlobalMaxPool1D()(output)\n",
    "    output = Dense(100, activation = args.activation)(output)\n",
    "    output = Dropout(args.dropout)(output)\n",
    "    preds = Dense(1, activation = 'sigmoid')(output)\n",
    "    model = Model(inputs, preds)\n",
    "    try:\n",
    "        model = multi_gpu_model(model, cpu_relocation = True)\n",
    "# model = multi_gpu_model(model, gpus = 2, cpu_relocation = True)\n",
    "        print('#'*50)\n",
    "        print('====> training using multiple gpu')\n",
    "        print('#'*50)\n",
    "    except:\n",
    "        print('#'*50)\n",
    "        print('====> training using single gpu or cpu')\n",
    "        print('#'*50)\n",
    "    return model\n",
    "\n",
    "def build_conv1d_model(args):\n",
    "    inputs = Input(shape=(args.max_length, ))\n",
    "    output = Embedding(vocab_size, 300, input_length=args.max_length)(inputs)\n",
    "    output = SpatialDropout1D(0.2)(output)\n",
    "    output = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(output)\n",
    "    output = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(output)\n",
    "    avg_pool = GlobalAveragePooling1D()(output)\n",
    "    max_pool = GlobalMaxPooling1D()(output)\n",
    "    output = concatenate([avg_pool, max_pool]) \n",
    "    output = Dense(64, activation='relu')(output)\n",
    "    output = Dropout(0.1)(output)\n",
    "    preds = Dense(1, activation=\"sigmoid\")(output)\n",
    "    model = Model(inputs, preds)\n",
    "    try:\n",
    "        model = multi_gpu_model(model, cpu_relocation = True)\n",
    "    # model = multi_gpu_model(model, gpus = 2, cpu_relocation = True)\n",
    "        print('#'*50)\n",
    "        print('====> training using multiple gpu')\n",
    "        print('#'*50)\n",
    "    except:\n",
    "        print('#'*50)\n",
    "        print('====> training using single gpu or cpu')\n",
    "        print('#'*50)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model/cp_{}.ckpt'.format(time.strftime('%Y-%m-%d',time.localtime(time.time())))\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback setup\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0,\n",
    "                          patience = 10,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                 factor = 0.1,\n",
    "                                 patience = 3,\n",
    "                                 min_lr = 0.00001)\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path,\n",
    "                             save_weights_only = True,\n",
    "                             save_best_only = True,\n",
    "                             verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "====> training using single gpu or cpu\n",
      "##################################################\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_17 (Embedding)     (None, 300, 300)          7833900   \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 300, 200)          320800    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_13 (Glo (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 8,174,901\n",
      "Trainable params: 8,174,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "args = argparse.ArgumentParser()\n",
    "# hyper parameter setup\n",
    "args.learner = 'adam'\n",
    "args.activation = 'relu'\n",
    "args.learning_rate = 0.001\n",
    "args.dropout = 0.3\n",
    "# args.max_length = max(len(l) for l in x_train)\n",
    "args.max_length = 300\n",
    "args.validation_split = 0.2\n",
    "args.epoch = 50\n",
    "args.train_batch_size = 512\n",
    "args.test_batch_size = 512\n",
    "args.embedding_matrix = None\n",
    "\n",
    "model = build_model(args)\n",
    "print(model.summary())\n",
    "\n",
    "if args.learner.lower() == \"adagrad\":\n",
    "    model.compile(optimizer=optimizers.Adagrad(lr=args.learning_rate),\n",
    "                 loss=losses.binary_crossentropy,\n",
    "                 metrics=[metrics.binary_accuracy])\n",
    "elif args.learner.lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=args.arglearning_rate),\n",
    "                 loss=losses.binary_crossentropy,\n",
    "                 metrics=[metrics.binary_accuracy])    \n",
    "elif args.learner.lower() == \"adam\":\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.learning_rate),\n",
    "                 loss=losses.binary_crossentropy,\n",
    "                 metrics=[metrics.binary_accuracy])\n",
    "else:\n",
    "    model.compile(optimizer=optimizers.SGD(lr=args.learning_rate),\n",
    "                 loss=losses.binary_crossentropy,\n",
    "                 metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39372 samples, validate on 9843 samples\n",
      "Epoch 1/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.3515 - binary_accuracy: 0.8474\n",
      "Epoch 00001: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 354s 9ms/sample - loss: 0.3496 - binary_accuracy: 0.8484 - val_loss: 0.1782 - val_binary_accuracy: 0.9366\n",
      "Epoch 2/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.1573 - binary_accuracy: 0.9488\n",
      "Epoch 00002: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 365s 9ms/sample - loss: 0.1576 - binary_accuracy: 0.9487 - val_loss: 0.1669 - val_binary_accuracy: 0.9384\n",
      "Epoch 3/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.1234 - binary_accuracy: 0.9637\n",
      "Epoch 00003: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 347s 9ms/sample - loss: 0.1232 - binary_accuracy: 0.9637 - val_loss: 0.1658 - val_binary_accuracy: 0.9419\n",
      "Epoch 4/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.1017 - binary_accuracy: 0.9703\n",
      "Epoch 00004: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 336s 9ms/sample - loss: 0.1013 - binary_accuracy: 0.9704 - val_loss: 0.1724 - val_binary_accuracy: 0.9397\n",
      "Epoch 5/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0869 - binary_accuracy: 0.9754\n",
      "Epoch 00005: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 347s 9ms/sample - loss: 0.0867 - binary_accuracy: 0.9754 - val_loss: 0.1900 - val_binary_accuracy: 0.9377\n",
      "Epoch 6/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0770 - binary_accuracy: 0.9784\n",
      "Epoch 00006: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 360s 9ms/sample - loss: 0.0770 - binary_accuracy: 0.9784 - val_loss: 0.1931 - val_binary_accuracy: 0.9380\n",
      "Epoch 7/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0604 - binary_accuracy: 0.9842\n",
      "Epoch 00007: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 364s 9ms/sample - loss: 0.0604 - binary_accuracy: 0.9842 - val_loss: 0.1976 - val_binary_accuracy: 0.9386\n",
      "Epoch 8/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0568 - binary_accuracy: 0.9851\n",
      "Epoch 00008: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 369s 9ms/sample - loss: 0.0572 - binary_accuracy: 0.9850 - val_loss: 0.2031 - val_binary_accuracy: 0.9383\n",
      "Epoch 9/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0556 - binary_accuracy: 0.9856\n",
      "Epoch 00009: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 377s 10ms/sample - loss: 0.0555 - binary_accuracy: 0.9856 - val_loss: 0.2064 - val_binary_accuracy: 0.9382\n",
      "Epoch 10/50\n",
      "38912/39372 [============================>.] - ETA: 5s - loss: 0.0530 - binary_accuracy: 0.9866 \n",
      "Epoch 00010: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 496s 13ms/sample - loss: 0.0530 - binary_accuracy: 0.9867 - val_loss: 0.2068 - val_binary_accuracy: 0.9374\n",
      "Epoch 11/50\n",
      "38912/39372 [============================>.] - ETA: 5:22 - loss: 0.0527 - binary_accuracy: 0.9868 \n",
      "Epoch 00011: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 27318s 694ms/sample - loss: 0.0528 - binary_accuracy: 0.9867 - val_loss: 0.2073 - val_binary_accuracy: 0.9373\n",
      "Epoch 12/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0529 - binary_accuracy: 0.9869 \n",
      "Epoch 00012: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 595s 15ms/sample - loss: 0.0529 - binary_accuracy: 0.9869 - val_loss: 0.2078 - val_binary_accuracy: 0.9375\n",
      "Epoch 13/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0525 - binary_accuracy: 0.9867Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 365s 9ms/sample - loss: 0.0531 - binary_accuracy: 0.9867 - val_loss: 0.2083 - val_binary_accuracy: 0.9374\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 1 layer bdlstm\n",
    "history = model.fit(x_train, y_train, \n",
    "              epochs=args.epoch, \n",
    "              batch_size=args.train_batch_size, \n",
    "              validation_split = args.validation_split, \n",
    "              callbacks = [earlystop, reduce_lr, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39372 samples, validate on 9843 samples\n",
      "Epoch 1/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.3366 - binary_accuracy: 0.8510 \n",
      "Epoch 00001: val_loss improved from inf to 0.17794, saving model to model/cp_2020-03-05.ckpt\n",
      "39372/39372 [==============================] - 596s 15ms/sample - loss: 0.3347 - binary_accuracy: 0.8520 - val_loss: 0.1779 - val_binary_accuracy: 0.9329\n",
      "Epoch 2/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.1553 - binary_accuracy: 0.9462 \n",
      "Epoch 00002: val_loss improved from 0.17794 to 0.16802, saving model to model/cp_2020-03-05.ckpt\n",
      "39372/39372 [==============================] - 599s 15ms/sample - loss: 0.1554 - binary_accuracy: 0.9463 - val_loss: 0.1680 - val_binary_accuracy: 0.9369\n",
      "Epoch 3/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.1211 - binary_accuracy: 0.9614 \n",
      "Epoch 00003: val_loss improved from 0.16802 to 0.16650, saving model to model/cp_2020-03-05.ckpt\n",
      "39372/39372 [==============================] - 590s 15ms/sample - loss: 0.1215 - binary_accuracy: 0.9612 - val_loss: 0.1665 - val_binary_accuracy: 0.9406\n",
      "Epoch 4/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.1025 - binary_accuracy: 0.9673 \n",
      "Epoch 00004: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 588s 15ms/sample - loss: 0.1025 - binary_accuracy: 0.9673 - val_loss: 0.1746 - val_binary_accuracy: 0.9384\n",
      "Epoch 5/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0894 - binary_accuracy: 0.9721 \n",
      "Epoch 00005: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 587s 15ms/sample - loss: 0.0903 - binary_accuracy: 0.9718 - val_loss: 0.1742 - val_binary_accuracy: 0.9386\n",
      "Epoch 6/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0782 - binary_accuracy: 0.9760 \n",
      "Epoch 00006: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 589s 15ms/sample - loss: 0.0786 - binary_accuracy: 0.9759 - val_loss: 0.1942 - val_binary_accuracy: 0.9364\n",
      "Epoch 7/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0602 - binary_accuracy: 0.9827 \n",
      "Epoch 00007: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 591s 15ms/sample - loss: 0.0599 - binary_accuracy: 0.9829 - val_loss: 0.1991 - val_binary_accuracy: 0.9351\n",
      "Epoch 8/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0574 - binary_accuracy: 0.9838 \n",
      "Epoch 00008: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 597s 15ms/sample - loss: 0.0573 - binary_accuracy: 0.9838 - val_loss: 0.2029 - val_binary_accuracy: 0.9346\n",
      "Epoch 9/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0558 - binary_accuracy: 0.9843 \n",
      "Epoch 00009: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 597s 15ms/sample - loss: 0.0558 - binary_accuracy: 0.9843 - val_loss: 0.2078 - val_binary_accuracy: 0.9341\n",
      "Epoch 10/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0532 - binary_accuracy: 0.9853 \n",
      "Epoch 00010: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 597s 15ms/sample - loss: 0.0532 - binary_accuracy: 0.9853 - val_loss: 0.2083 - val_binary_accuracy: 0.9342\n",
      "Epoch 11/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0522 - binary_accuracy: 0.9858 \n",
      "Epoch 00011: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 597s 15ms/sample - loss: 0.0527 - binary_accuracy: 0.9857 - val_loss: 0.2094 - val_binary_accuracy: 0.9344\n",
      "Epoch 12/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0526 - binary_accuracy: 0.9855 \n",
      "Epoch 00012: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 597s 15ms/sample - loss: 0.0529 - binary_accuracy: 0.9853 - val_loss: 0.2102 - val_binary_accuracy: 0.9342\n",
      "Epoch 13/50\n",
      "38912/39372 [============================>.] - ETA: 6s - loss: 0.0521 - binary_accuracy: 0.9854 Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16650\n",
      "39372/39372 [==============================] - 598s 15ms/sample - loss: 0.0522 - binary_accuracy: 0.9853 - val_loss: 0.2111 - val_binary_accuracy: 0.9345\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 2 layer bdlstm\n",
    "history = bdlstm_model.fit(x_train, y_train, \n",
    "              epochs=args.epoch, \n",
    "              batch_size=args.train_batch_size, \n",
    "              validation_split = args.validation_split, \n",
    "              callbacks = [earlystop, reduce_lr, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39372 samples, validate on 9843 samples\n",
      "Epoch 1/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.3001 - binary_accuracy: 0.8685\n",
      "Epoch 00001: val_loss improved from inf to 0.16199, saving model to model/cp_2020-03-05.ckpt\n",
      "39372/39372 [==============================] - 368s 9ms/sample - loss: 0.2985 - binary_accuracy: 0.8694 - val_loss: 0.1620 - val_binary_accuracy: 0.9382\n",
      "Epoch 2/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.1407 - binary_accuracy: 0.9528\n",
      "Epoch 00002: val_loss improved from 0.16199 to 0.15599, saving model to model/cp_2020-03-05.ckpt\n",
      "39372/39372 [==============================] - 362s 9ms/sample - loss: 0.1404 - binary_accuracy: 0.9529 - val_loss: 0.1560 - val_binary_accuracy: 0.9412\n",
      "Epoch 3/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.1080 - binary_accuracy: 0.9656\n",
      "Epoch 00003: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 383s 10ms/sample - loss: 0.1078 - binary_accuracy: 0.9656 - val_loss: 0.1573 - val_binary_accuracy: 0.9419\n",
      "Epoch 4/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0875 - binary_accuracy: 0.9727 \n",
      "Epoch 00004: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 432s 11ms/sample - loss: 0.0876 - binary_accuracy: 0.9726 - val_loss: 0.1848 - val_binary_accuracy: 0.9367\n",
      "Epoch 5/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0698 - binary_accuracy: 0.9781\n",
      "Epoch 00005: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 406s 10ms/sample - loss: 0.0696 - binary_accuracy: 0.9782 - val_loss: 0.1928 - val_binary_accuracy: 0.9368\n",
      "Epoch 6/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0508 - binary_accuracy: 0.9852\n",
      "Epoch 00006: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 392s 10ms/sample - loss: 0.0511 - binary_accuracy: 0.9852 - val_loss: 0.1975 - val_binary_accuracy: 0.9374\n",
      "Epoch 7/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0464 - binary_accuracy: 0.9872\n",
      "Epoch 00007: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 412s 10ms/sample - loss: 0.0464 - binary_accuracy: 0.9872 - val_loss: 0.2003 - val_binary_accuracy: 0.9372\n",
      "Epoch 8/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0450 - binary_accuracy: 0.9873\n",
      "Epoch 00008: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 419s 11ms/sample - loss: 0.0448 - binary_accuracy: 0.9873 - val_loss: 0.2060 - val_binary_accuracy: 0.9363\n",
      "Epoch 9/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0424 - binary_accuracy: 0.9883\n",
      "Epoch 00009: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 420s 11ms/sample - loss: 0.0424 - binary_accuracy: 0.9882 - val_loss: 0.2067 - val_binary_accuracy: 0.9356\n",
      "Epoch 10/50\n",
      "38912/39372 [============================>.] - ETA: 4s - loss: 0.0421 - binary_accuracy: 0.9883\n",
      "Epoch 00010: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 385s 10ms/sample - loss: 0.0422 - binary_accuracy: 0.9883 - val_loss: 0.2078 - val_binary_accuracy: 0.9356\n",
      "Epoch 11/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0421 - binary_accuracy: 0.9884\n",
      "Epoch 00011: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 364s 9ms/sample - loss: 0.0422 - binary_accuracy: 0.9884 - val_loss: 0.2083 - val_binary_accuracy: 0.9358\n",
      "Epoch 12/50\n",
      "38912/39372 [============================>.] - ETA: 3s - loss: 0.0417 - binary_accuracy: 0.9888Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.15599\n",
      "39372/39372 [==============================] - 365s 9ms/sample - loss: 0.0415 - binary_accuracy: 0.9888 - val_loss: 0.2088 - val_binary_accuracy: 0.9360\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "# conv1d_model\n",
    "history = model.fit(x_train, y_train, \n",
    "              epochs=args.epoch, \n",
    "              batch_size=args.train_batch_size, \n",
    "              validation_split = args.validation_split, \n",
    "              callbacks = [earlystop, reduce_lr, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
